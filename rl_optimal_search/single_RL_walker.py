# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/q_learning.ipynb (unless otherwise specified).

__all__ = ['target_env']

# Cell
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from .single_LW_walker import isBetween_c_Vec, isBetween

# Cell
class target_env():
    def __init__(self,
                 Nt = 1000,
                 L = 200,
                 at = 1,
                 ls = 2,
                 agent_step = 1,
                 boundary_condition = 'periodic'):

        self.Nt = Nt
        self.L = L
        self.at = at
        self.ls = ls
        self.boundary_condition = boundary_condition

        self.init_env()

        self.agent_step = agent_step
        self.current_direction = torch.rand(1)*2*np.pi

        self.agent_state = 0

    def init_env(self):
        self.target_positions = torch.rand(self.Nt, 2)*self.L
        self.agent_pos = torch.rand(2)*self.L
        self.previous_pos = self.agent_pos.clone()

    def update_pos(self, direction):

        # Save previous position to check if crossing happened
        self.previous_pos = self.agent_pos.clone()

        self.agent_pos[0] = self.agent_pos[0] + self.agent_step*np.cos(direction)
        self.agent_pos[1] = self.agent_pos[1] + self.agent_step*np.sin(direction)

        self.check_bc()

    def check_encounter(self):
        encounters = isBetween_c_Vec(self.agent_pos, self.previous_pos, self.target_positions, epsilon = self.at)

        if sum(encounters) > 0:
            distance_previous_pos = np.sqrt((self.agent_pos[0]-self.target_positions[:, 0])**2 + (self.agent_pos[1]-self.target_positions[:, 1])**2)

            # checking which encountered point is closer to previous position
            min_distance_masked = np.argmin(distance_previous_pos[encounters])
            first_encounter = np.arange(self.Nt)[encounters][min_distance_masked]

            # If there was encounter, we reset direction and change position of particle to (pos target + ls)
            self.current_direction = np.random.uniform(low = 0, high = 2*np.pi)
            self.agent_pos[0] = self.target_positions[first_encounter, 0] + self.ls*np.cos(self.current_direction)
            self.agent_pos[1] = self.target_positions[first_encounter, 1] + self.ls*np.sin(self.current_direction)

            # Update the state of the agent
            self.agent_state = 0

            self.check_bc()

            return 1

        else: return 0

    def check_bc(self):
        if self.boundary_condition == 'reflectant':
            while torch.max(self.agent_pos) > self.L or torch.min(self.agent_pos)< 0:
                self.agent_pos[self.agent_pos > self.L] = self.agent_pos[self.agent_pos > self.L] - 2*(self.agent_pos[self.agent_pos > self.L] - self.L)
                self.agent_pos[self.agent_pos < 0] = - self.agent_pos[self.agent_pos < 0]


        elif self.boundary_condition == 'periodic':
            while torch.max(self.agent_pos) > self.L or torch.min(self.agent_pos)< 0:
                self.agent_pos[self.agent_pos > self.L] = self.agent_pos[self.agent_pos > self.L] - self.L
                self.agent_pos[self.agent_pos < 0] = self.L + self.agent_pos[self.agent_pos < 0]


