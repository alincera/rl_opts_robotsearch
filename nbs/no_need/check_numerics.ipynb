{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32081dac-9683-42fc-96c9-63ca5acb04b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl_optimal_search.environment import *\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from scipy.special import zeta\n",
    "import pathlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4be78859-08a0-49e9-a526-a7f111a26cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecd9d39f-25ed-476a-abe7-5362866c5d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def powerlaw(beta, l):\n",
    "    \"\"\" Normalized discrete powerlaw \"\"\"\n",
    "    return (1/zeta(beta+1, q=1)) * l ** (-1-beta)\n",
    "\n",
    "def double_exp(parameters, l):\n",
    "    \"\"\" Normalized discrete double exponential \"\"\"\n",
    "    \n",
    "    d_int, d_ext, p = parameters\n",
    "    gamma_int = 1/d_int\n",
    "    gamma_ext = 1/d_ext\n",
    "    \n",
    "    return p * (1-np.exp(-gamma_int)) * np.exp(-gamma_int * (l-1)) + (1-p) * (1-np.exp(-gamma_ext)) * np.exp(-gamma_ext * (l-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e646d5c-4ce9-448e-9c89-07c654deaf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl_optimal_search.theoretical_policy import get_ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0bbb163-019f-481c-9f60-dcf62a28951d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_from_distr(parameters, max_length, model):\n",
    "    \"\"\"\n",
    "    Gets policy from a given probability distribution.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    parameters : (list for double_exp, float for powerlaw) parameters of the distribution\n",
    "    max_length : (int) maximum length value for which the policy is computed\n",
    "    model : (str) Theoretical model. Options: 'double_exp', 'powerlaw'\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    policy : (list) policy starting from the counter at l=1.\n",
    "        \n",
    "    \"\"\"\n",
    "    policy = [1]\n",
    "    for length in range(1, max_length+1):\n",
    "        if model == 'powerlaw':\n",
    "            policy.append(1 - powerlaw(parameters, length) / np.prod(policy))\n",
    "        elif model == 'double_exp':\n",
    "            policy.append(1 - double_exp(parameters, length) / np.prod(policy))\n",
    "        \n",
    "    policy = policy[1:]\n",
    "    \n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78d046ae-5ad2-4e61-83f4-fa68fe8df204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_from_policy(config):\n",
    "    '''\n",
    "    Walk of foragers given a probability distribution of step lengths. Performance is evaluated as the number of targets found in a fixed time.\n",
    "    \n",
    "    Input\n",
    "    -------\n",
    "    config: (dict) config dict with parameters\n",
    "    \n",
    "    Description of parameters in config\n",
    "    ------------------------------------\n",
    "    time_ep: (int) Number of steps (decisions)\n",
    "    n: (int) number of agents\n",
    "    kick: (float) agent is displaced a distance of kick from the target when it finds it\n",
    "    model: (str) type of model. Options: 'powerlaw', 'double_exp'\n",
    "    Nt: (int) number of targets\n",
    "    L: (int) world size\n",
    "    at:  (int/float) radius of the targets\n",
    "    destructive:  (bool) True if targets are destructive\n",
    "                     \n",
    "    '''\n",
    "    \n",
    "    #get parameters of the distributions depending on the chosen model\n",
    "    if config['model'] == 'powerlaw':\n",
    "        parameters = config['beta']\n",
    "    elif config['model'] == 'double_exp':\n",
    "        parameters = [config['d_int'], config['d_ext'], config['p']]\n",
    "        \n",
    "    #get policy: probability of staying in same direction at each time. \n",
    "    policy = policy_from_distr(parameters, max_length=config['time_ep'], model=config['model'])\n",
    "    \n",
    "    reward = [0] * config['n']\n",
    "    \n",
    "    for ag in tqdm(range(config['n'])):\n",
    "        #initialize agents clock, position and direction, as well as targets in the env.\n",
    "        pos = np.zeros((config['time_ep'], 2))\n",
    "        pos[0] = np.random.rand(2)*config['L'] \n",
    "        direction = np.random.rand()*2*np.pi \n",
    "        \n",
    "        internal_clock = 0 #which corresponds to l=1\n",
    "        target_positions = np.random.rand(config['Nt'],2) * config['L']\n",
    "        \n",
    "        for t in range(1, config['time_ep']):   \n",
    "            \n",
    "            #update position\n",
    "            pos[t, 0] = pos[t-1, 0] + np.cos(direction)\n",
    "            pos[t, 1] = pos[t-1, 1] + np.sin(direction)\n",
    "            \n",
    "            pos[t] %= config['L']\n",
    "            \n",
    "            #check reward\n",
    "            encounters = get_encounters(pos[t-1], pos[t], target_positions, config['L'], config['at'])\n",
    "        \n",
    "            kick = False\n",
    "            \n",
    "            if sum(encounters) > 0: \n",
    "                \n",
    "                first_encounter = np.arange(len(target_positions))[encounters]\n",
    "                \n",
    "                if config['destructive']:\n",
    "                    #target is destroyed, sample position for a new target.\n",
    "                    target_positions[first_encounter] = np.random.rand(1,2) * config['L']\n",
    "                else:\n",
    "                \n",
    "                    #----KICK----\n",
    "                    # If there was an encounter, we reset direction and change position of particle to (pos target + ls)\n",
    "                    kick_direction = np.random.rand()*2*np.pi  \n",
    "                    pos[t,  0] = (target_positions[first_encounter, 0] + config['kick']*np.cos(kick_direction))%config['L']\n",
    "                    pos[t,  1] = (target_positions[first_encounter, 1] + config['kick']*np.sin(kick_direction))%config['L']\n",
    "                    #------------\n",
    "                \n",
    "                reward[ag] += 1\n",
    "                kick = True\n",
    "                \n",
    "                \n",
    "                    \n",
    "                 \n",
    "            if np.random.rand() > policy[internal_clock] or kick:\n",
    "                internal_clock = 0\n",
    "                direction = np.random.rand()*2*np.pi  \n",
    "                \n",
    "            else:\n",
    "                internal_clock += 1\n",
    "                \n",
    "        \n",
    "    mean_reward = np.mean(reward)\n",
    "    \n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb1f63a3-752b-4d17-afec-605f88690832",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'d_int': 0.5,\n",
    "          'd_ext': 40,\n",
    "          'p': 0.5,\n",
    "          'beta': 0.8,#tune.uniform(0.0000001, 1),\n",
    "          'model': 'double_exp',\n",
    "          'time_ep': 3000,\n",
    "          'n': 5000,\n",
    "          'kick': 10.0,\n",
    "          'Nt': 100,\n",
    "          'L': 100,\n",
    "          'at': 0.5,\n",
    "          'destructive': False\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61dd3188-d20e-43da-8592-94d4f6090fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b61620901b724c79b4aa55098b5cb8e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = walk_from_policy(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56d1572c-22a1-41b7-8303-ea94514c29e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_positions = np.random.rand(config['Nt'],2) * config['L']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ps_gnn",
   "language": "python",
   "name": "ps_gnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
