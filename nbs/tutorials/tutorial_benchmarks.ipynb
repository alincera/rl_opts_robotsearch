{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider as benchmark models the discrete Lévy distribution and the bi-exponential distribution, given by equations\n",
    "\n",
    "$$\\Pr(L)=\\zeta^{-1}_{(1+\\beta, 1)} L^{-1-\\beta}\\,,$$ and $$\\Pr(L) = \\sum_{i=1,2} \\omega_i (1-e^{-1/d_i}) e^{-(L-1)/d_i} \\, ,$$ respectively, where $\\zeta_{(1+\\beta, 1)}=\\sum_{\\ell=0}^\\infty (\\ell+1)^{-1-\\beta}$ is the Riemann zeta function, $d_i$ are length scales and the mode weights satisfy $\\sum_{i=1,2} \\omega_i=1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We transform the step length distributions into policies with Eq. (5), which is implemented in the code with the method ``policy_from_distr``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl_opts.utils_distributions import policy_from_distr, powerlaw, double_exp\n",
    "\n",
    "#get policy from benchmark model\n",
    "policy = policy_from_distr(parameters, max_length, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method inputs (i) the parameter/s of the model, which is the exponent $\\beta$ for the Lévy distribution and $d_1$, $d_2$, $\\omega_1$ for the bi-exponential; (ii) the maximum value of step counter; and (iii) the model (either 'powerlaw' or 'double_exp')."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We employ the library ``Tune`` for parameter optimization, which allows us to optimize the average search efficiency over a number a walks ``mean_eff`` with respect to the model parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHANGE:\n",
    "The function ``mean_eff`` to optimize is computed via ``average_search_efficiency``, and then reported to ``tune``. All this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl_opts.learn_and_bench import average_search_efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The efficiency of each walk is again computed with ``walk_from_policy`` (see also tutorial on learning), but in this case, the policy is obtained from the benchmark distribution. Note that we save the efficiency achieved in each walk to be able to later retrieve the mean and the SEM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the input config is a dictionary with the parameter ranges that the optimization algorithm will consider. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters of that dictionary are described below:\n",
    "\n",
    "Model (we input parameter ranges here):\n",
    "\n",
    "- `d_int` : small scale ($d_1$, first mode) of the bi-exponential distribution \\\n",
    "- `d_ext` : large scale ($d_2$, second mode) of the bi-exponential distribution \\\n",
    "- `p` : weight of the first mode ($\\omega_1$) in the bi-exponential distribution \\\n",
    "- `beta` : exponent of the Lévy distribution \\\n",
    "- `model` : model description (either 'powerlaw' or 'double_exp')\n",
    "\n",
    "Walks (we input a single value that is fixed throughout the optimization):\n",
    "\n",
    "- `time_ep` : number of (small, $d=1$) steps per walk. We choose the same value for the benchmarks as for the episodes in the RL training \\\n",
    "- `n` : number of walks (also referred to as agents in the code, but there is no relation to RL agents)\n",
    "\n",
    "Environment (we input a single value that is fixed throughout the optimization):\n",
    "\n",
    "- `lc` : cutoff length \\\n",
    "- `Nt` : number of targets \\\n",
    "- `L` : world size \\\n",
    "- `r` : target detection radius \\\n",
    "- `destructive` : whether targets are destructive or not (always set to False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we define the parameter ranges, we choose the optimization algorithm. Among the different possibilities that ``Tune`` offers, we chose Grid Search for the Lévy distribution and Bayesian Optimization for the bi-exponential distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us take the example with $l_\\textrm{c}=3$.\n",
    "\n",
    "For the Lévy distribution, the config dictionary looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'d_int': None,\n",
    "          'd_ext': None,\n",
    "          'p': None,\n",
    "          'beta': tune.grid_search(np.linspace(0.01,1.,20)), \n",
    "          'model': 'powerlaw',\n",
    "          'time_ep': 20000,\n",
    "          'n': 10000,\n",
    "          'lc': 3.0,\n",
    "          'Nt': 100,\n",
    "          'L': 100,\n",
    "          'r': 0.5,\n",
    "          'destructive': False\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do a grid search over 20 parameters, linearly spaced in the interval $[0.01, 1]$. Parameters that correspond to the other model are set to 'None'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we initialize the tuner, which by default does a grid search over the input parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "\n",
    "tuner = tune.Tuner(average_search_efficiency,\n",
    "                   tune_config=tune.TuneConfig(num_samples=1),\n",
    "                   param_space=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we run the algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_grid = tuner.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the bi-exponential distribution, the config dictionary looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'d_int': tune.uniform(0.00001, 20.0),\n",
    "          'd_ext': 100.0,\n",
    "          'p': tune.uniform(0.0, 1.0),\n",
    "          'beta': None,\n",
    "          'model': 'double_exp',\n",
    "          'time_ep': 20000,\n",
    "          'n': 10000,\n",
    "          'lc': 3.0,\n",
    "          'Nt': 100,\n",
    "          'L': 100,\n",
    "          'r': 0.5,\n",
    "          'destructive': False\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, since we choose a Bayesian optimization method, we do not specify the parameters to try, but just the ranges. For the small scale, we consider a range that is of the order of the scale of $l_\\textrm{c}$. We fix the value for $d_2$ to further guide the search and make it more time efficient. We do the search with $d_2=100$, which is the scale of the average distance between targets, and with $d_2=10^5$. Again, the parameter $\\beta$ that corresponds to the other model is set to 'None'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first initialize the Bayesian optimization method, and then the tuner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "from ray.tune.search.bayesopt import BayesOptSearch\n",
    "from ray.tune.search import ConcurrencyLimiter\n",
    "\n",
    "bayesopt = BayesOptSearch(metric=\"mean_eff\", mode=\"max\")\n",
    "bayesopt = ConcurrencyLimiter(bayesopt, max_concurrent=3)\n",
    "tuner = tune.Tuner(average_search_efficiency, \n",
    "                   tune_config=tune.TuneConfig(search_alg=bayesopt, num_samples=100), \n",
    "                   param_space=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we limit the number of concurrent processes to 3, so that the method can update itself more times within the 100 samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_grid = tuner.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are saved as a panda dataframe in the folder 'results/benchmark_models/'. We further identify each run of the algorithm with the parameter `run`, in case there is more than one run per model (e.g. for the bi-exponential, we run it twice, for each value of $d_2$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = '0'\n",
    "results_path = 'results/benchmark_models/' + config['model'] + '/'+ str(config['lc']) + '/run_'+run+'/'\n",
    "\n",
    "results_df = result_grid.get_dataframe()\n",
    "results_df.to_csv(results_path+'df'+run+'_'+config['model']+'_lc_'+str(config['lc'])+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To retrieve these results, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results_df = pd.read_csv(results_path+'df'+run+'_'+config['model']+'_lc_'+str(config['lc'])+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, the model parameters that achieved the best performance, together with the corresponding mean search efficiency, and its standard error of the mean (which is the only value that is not contained in the dataframe results_df), can be obtained by running the method `get_opt`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl_opts.utils import get_opt\n",
    "\n",
    "main_path = 'results/benchmark_models/'\n",
    "lc = 3.0 #note that this notation has to match with how you have input it in the config dictionary\n",
    "model = 'powerlaw'\n",
    "run = '0'\n",
    "\n",
    "mean_eff, sem, parameters = get_opt(main_path, lc, model, run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The config dictionaries can also be saved and retrieved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'configurations/benchmark_models/'\n",
    "\n",
    "np.save(config_path+'config_'+config['model']+'_lc_'+str(config['lc'])+'_run_'+run+'.npy', config)\n",
    "np.load(config_path+'config_'+config['model']+'_lc_'+str(config['lc'])+'_run_'+run+'.npy', allow_pickle=True).item()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optimal_search",
   "language": "python",
   "name": "optimal_search"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
